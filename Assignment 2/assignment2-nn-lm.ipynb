{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling Literate [98b081ad-f1c9-55d3-8b20-4c87d4299306]\n",
      "└ @ Base loading.jl:1278\n"
     ]
    }
   ],
   "source": [
    "using Knet, Base.Iterators, IterTools, LinearAlgebra, StatsBase, Test, Literate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"nn4nlp-code/data/ptb\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const datadir = \"nn4nlp-code/data/ptb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "@size (macro with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro size(z, s); esc(:(@assert (size($z) == $s) string(summary($z),!=,$s))); end # for debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Vocab\n",
    "    w2i::Dict{String,Int}\n",
    "    i2w::Vector{String}\n",
    "    unk::Int\n",
    "    eos::Int\n",
    "    tokenizer\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vocab"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function Vocab(file::String; tokenizer=split, vocabsize=Inf, mincount=1, unk=\"<unk>\", eos=\"<s>\")\n",
    "    # read file \n",
    "    f = open(file, \"r\")\n",
    "    sents = read(f, String)\n",
    "    tokenized_sents = tokenizer(sents)\n",
    "    # count number of words\n",
    "    w2i = Dict()\n",
    "    i2w = []\n",
    "    cnt = Dict()\n",
    "    if unk != nothing\n",
    "        w2i[unk] = length(i2w) + 1\n",
    "        push!(i2w, unk)\n",
    "    end\n",
    "    \n",
    "    if eos != nothing\n",
    "        w2i[eos] = length(i2w) + 1\n",
    "        push!(i2w, eos)\n",
    "    end\n",
    "    \n",
    "    # count words \n",
    "    for word in tokenized_sents\n",
    "        cnt[word] = get!(cnt, word, 0) + 1\n",
    "    end\n",
    "    for word in tokenized_sents\n",
    "        if !haskey(w2i, word)\n",
    "            w2i[word] = length(i2w) + 1\n",
    "            push!(i2w, word)\n",
    "        end\n",
    "    end\n",
    "    close(f)\n",
    "    \n",
    "    return Vocab(w2i, i2w, unk != nothing ? w2i[unk] : -1, eos != nothing ? w2i[eos] : -1, tokenizer)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Testing Vocab\n",
      "└ @ Main In[37]:1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\u001b[1mTest Failed\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[37]:6\u001b[22m\n",
      "  Expression: length((Vocab(f, vocabsize = 1234)).i2w) == 1234\n",
      "   Evaluated: 10000 == 1234\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mThere was an error during testing\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mThere was an error during testing\u001b[39m",
      "",
      "Stacktrace:",
      " [1] record(::Test.FallbackTestSet, ::Union{Test.Error, Test.Fail}) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:737",
      " [2] do_test(::Test.ExecutionResult, ::Any) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:520",
      " [3] top-level scope at In[37]:6",
      " [4] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "@info \"Testing Vocab\"\n",
    "f = \"$datadir/train.txt\"\n",
    "v = Vocab(f)\n",
    "@test all(v.w2i[w] == i for (i,w) in enumerate(v.i2w))\n",
    "@test length(Vocab(f).i2w) == 10000\n",
    "@test length(Vocab(f, vocabsize=1234).i2w) == 1234\n",
    "@test length(Vocab(f, mincount=5).i2w) == 9859"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: generating notebook from `~/Desktop/Courses/NLP-Comp541/Assignments/Assignment 2/nn-lm.jl`\n",
      "└ @ Literate /Users/moayedhajiali/.julia/packages/Literate/kB2Gm/src/Literate.jl:325\n",
      "┌ Info: writing result to `~/Desktop/Courses/NLP-Comp541/Assignments/Assignment 2/nn-lm.ipynb`\n",
      "└ @ Literate /Users/moayedhajiali/.julia/packages/Literate/kB2Gm/src/Literate.jl:368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"/Users/moayedhajiali/Desktop/Courses/NLP-Comp541/Assignments/Assignment 2/nn-lm.ipynb\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Literate.notebook(\"nn-lm.jl\", \".\", execute=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
