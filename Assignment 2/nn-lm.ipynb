{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Neural Probabilistic Language Model\n",
    "\n",
    "Reference: Bengio, Y., Ducharme, R., Vincent, P., & Jauvin, C. (2003). A neural probabilistic language model. *Journal of machine learning research, 3*. (Feb), 1137-1155. ([PDF](http://www.jmlr.org/papers/v3/bengio03a.html), [Sample code](https://github.com/neubig/nn4nlp-code/blob/master/02-lm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "@size (macro with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Knet, Base.Iterators, IterTools, LinearAlgebra, StatsBase, Test\n",
    "macro size(z, s); esc(:(@assert (size($z) == $s) string(summary($z),!=,$s))); end # for debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `datadir` to the location of ptb on your filesystem. You can find the ptb data in the\n",
    "https://github.com/neubig/nn4nlp-code repo\n",
    "[data](https://github.com/neubig/nn4nlp-code/tree/master/data) directory. The code below\n",
    "clones the nn4nlp-code repo using `git clone https://github.com/neubig/nn4nlp-code.git` if\n",
    "the data directory does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const datadir = \"nn4nlp-code/data/ptb\"\n",
    "isdir(datadir) || run(`git clone https://github.com/neubig/nn4nlp-code.git`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Vocabulary\n",
    "\n",
    "In this part we are going to implement a `Vocab` type that will map words to unique integers. The fields of `Vocab` are:\n",
    "* w2i: A dictionary from word strings to integers.\n",
    "* i2w: An array mapping integers to word strings.\n",
    "* unk: The integer id of the unknown word token.\n",
    "* eos: The integer id of the end of sentence token.\n",
    "* tokenizer: The function used to tokenize sentence strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Vocab\n",
    "    w2i::Dict{String,Int}\n",
    "    i2w::Vector{String}\n",
    "    unk::Int\n",
    "    eos::Int\n",
    "    tokenizer\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocab constructor\n",
    "\n",
    "Implement a constructor for the `Vocab` type. The constructor should take a file path as\n",
    "an argument and create a `Vocab` object with the most frequent words from that file and\n",
    "optionally unk and eos tokens. The keyword arguments are:\n",
    "\n",
    "* tokenizer: The function used to tokenize sentence strings.\n",
    "* vocabsize: Maximum number of words in the vocabulary.\n",
    "* mincount: Minimum count of words in the vocabulary.\n",
    "* unk, eos: unk and eos strings, should be part of the vocabulary unless set to nothing.\n",
    "\n",
    "You may find the following Julia functions useful: `Dict`, `eachline`, `split`, `get`,\n",
    "`delete!`, `sort!`, `keys`, `collect`, `push!`, `pushfirst!`, `findfirst`. You can take\n",
    "look at their documentation using e.g. `@doc eachline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vocab"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function Vocab(file::String; tokenizer=split, vocabsize=Inf, mincount=1, unk=\"<unk>\", eos=\"<s>\")\n",
    "    # read file \n",
    "    f = open(file, \"r\")\n",
    "    sents = read(f, String)\n",
    "    tokenized_sents = tokenizer(sents)\n",
    "    # count number of words\n",
    "    w2i = Dict()\n",
    "    i2w = []\n",
    "    cnt = Dict()\n",
    "    if unk != nothing\n",
    "        w2i[unk] = length(i2w) + 1\n",
    "        push!(i2w, unk)\n",
    "    end\n",
    "    \n",
    "    if eos != nothing\n",
    "        w2i[eos] = length(i2w) + 1\n",
    "        push!(i2w, eos)\n",
    "    end\n",
    "    \n",
    "    # count words \n",
    "    for word in tokenized_sents\n",
    "        cnt[word] = get!(cnt, word, 0) + 1\n",
    "    end\n",
    "    \n",
    "    # sort according to occurances\n",
    "    words = reverse(sort(collect(cnt), by=x->x[2]))\n",
    "    for (word, word_cnt) in words\n",
    "        if length(w2i) >= vocabsize\n",
    "            break\n",
    "        end\n",
    "        \n",
    "        if word_cnt >= mincount && !haskey(w2i, word)\n",
    "            w2i[word] = length(i2w) + 1\n",
    "            push!(i2w, word)\n",
    "        end\n",
    "    end\n",
    "    close(f)\n",
    "    \n",
    "    return Vocab(w2i, i2w, unk != nothing ? w2i[unk] : -1, eos != nothing ? w2i[eos] : -1, tokenizer)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Testing Vocab\n",
      "└ @ Main In[5]:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@info \"Testing Vocab\"\n",
    "f = \"$datadir/train.txt\"\n",
    "v = Vocab(f)\n",
    "@test all(v.w2i[w] == i for (i,w) in enumerate(v.i2w))\n",
    "@test length(Vocab(f).i2w) == 10000\n",
    "@test length(Vocab(f, vocabsize=1234).i2w) == 1234\n",
    "@test length(Vocab(f, mincount=5).i2w) == 9859"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the training data as our vocabulary source for the rest of the assignment. It\n",
    "has already been tokenized, lowercased, and words other than the most frequent 10000 have\n",
    "been replaced with `\"<unk>\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vocab(Dict(\"adviser\" => 1776,\"enjoy\" => 4828,\"advertisements\" => 8569,\"fight\" => 1462,\"nicholas\" => 3919,\"everywhere\" => 6720,\"surveyed\" => 3661,\"helping\" => 2116,\"whose\" => 625,\"manufacture\" => 5278…), [\"<unk>\", \"<s>\", \"the\", \"N\", \"of\", \"to\", \"a\", \"in\", \"and\", \"'s\"  …  \"swapo\", \"nahb\", \"kia\", \"wachter\", \"rubens\", \"isi\", \"aer\", \"centrust\", \"snack-food\", \"sim\"], 1, 2, split)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vocab = Vocab(\"$datadir/train.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. TextReader\n",
    "\n",
    "Next we will implement `TextReader`, an iterator that reads sentences from a file and\n",
    "returns them as integer arrays using a `Vocab`.  We want to implement `TextReader` as an\n",
    "iterator for scalability. Instead of reading the whole file at once, `TextReader` will\n",
    "give us one sentence at a time as needed (similar to how `eachline` works). This will help\n",
    "us handle very large files in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct TextReader\n",
    "    file::String\n",
    "    vocab::Vocab\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iterate\n",
    "\n",
    "The main function to implement for a new iterator is `iterate`. The `iterate` function\n",
    "takes an iterator and optionally a state, and returns a `(nextitem,state)` if the iterator\n",
    "has more items or `nothing` otherwise. A one argument call `iterate(x)` starts the\n",
    "iteration, and a two argument call `iterate(x,state)` continues from where it left off.\n",
    "\n",
    "Here are some sources you may find useful on iterators:\n",
    "\n",
    "* https://github.com/denizyuret/Knet.jl/blob/master/tutorial/25.iterators.ipynb\n",
    "* https://docs.julialang.org/en/v1/manual/interfaces\n",
    "* https://docs.julialang.org/en/v1/base/collections/#lib-collections-iteration-1\n",
    "* https://docs.julialang.org/en/v1/base/iterators\n",
    "* https://docs.julialang.org/en/v1/manual/arrays/#Generator-Expressions-1\n",
    "* https://juliacollections.github.io/IterTools.jl/stable\n",
    "\n",
    "For `TextReader` the state should be an `IOStream` object obtained by `open(file)` at the\n",
    "start of the iteration. When `eof(state)` indicates that end of file is reached, the\n",
    "stream should be closed by `close(state)` and `nothing` should be returned. Otherwise\n",
    "`TextReader` reads the next line from the file using `readline`, tokenizes it, maps each\n",
    "word to its integer id using the vocabulary and returns the resulting integer array\n",
    "struct Xnorm; itr; end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "function Base.iterate(r::TextReader, s=nothing)\n",
    "    if s == nothing\n",
    "        #open a new IO\n",
    "        s = open(r.file, \"r\")\n",
    "    end\n",
    "    eof(s) && return nothing\n",
    "    \n",
    "    line = readline(s)\n",
    "    tokenized_line = r.vocab.tokenizer(line)\n",
    "    return (get.((r.vocab.w2i,), collect(tokenized_line), (r.vocab.unk,)), s)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are some optional functions that can be defined for iterators. They are required for\n",
    "`collect` to work, which converts an iterator to a regular array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base.IteratorSize(::Type{TextReader}) = Base.SizeUnknown()\n",
    "Base.IteratorEltype(::Type{TextReader}) = Base.HasEltype()\n",
    "Base.eltype(::Type{TextReader}) = Vector{Int}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Testing TextReader\n",
      "└ @ Main In[10]:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@info \"Testing TextReader\"\n",
    "train_sentences, valid_sentences, test_sentences =\n",
    "    (TextReader(\"$datadir/$file.txt\", train_vocab) for file in (\"train\",\"valid\",\"test\"))\n",
    "@test length(first(train_sentences)) == 24\n",
    "@test length(collect(train_sentences)) == 42068\n",
    "@test length(collect(valid_sentences)) == 3370\n",
    "@test length(collect(test_sentences)) == 3761"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Model\n",
    "\n",
    "We are going to first implement some reusable layers for our model. Layers and models are\n",
    "basically functions with associated parameters. Please review [Function-like\n",
    "objects](https://docs.julialang.org/en/v1/manual/methods/#Function-like-objects-1) for how\n",
    "to best define such objects in Julia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed\n",
    "\n",
    "`Embed` is a layer that takes an integer or an array of integers as input, uses them as\n",
    "column indices to lookup embeddings in its parameter matrix `w`, and returns these columns\n",
    "packed into an array. If the input size is `(X1,X2,...)`, the output size will be\n",
    "`(C,X1,X2,...)` where C is the columns size of `w` (which Julia will automagically\n",
    "accomplish if you use the right indexing expression). Please review [Array\n",
    "indexing](https://docs.julialang.org/en/v1/manual/arrays/#man-array-indexing-1) and the\n",
    "Knet `param` function to implement this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Embed; w; end\n",
    "\n",
    "function Embed(vocabsize::Int, embedsize::Int)\n",
    "    return Embed(rand(embedsize, vocabsize))\n",
    "end\n",
    "\n",
    "function (l::Embed)(x)\n",
    "    return l.w[:, x]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Testing Embed\n",
      "└ @ Main In[12]:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@info \"Testing Embed\"\n",
    "Knet.seed!(1)\n",
    "embed = Embed(100,10)\n",
    "input = rand(1:100, 2, 3)\n",
    "output = embed(input)\n",
    "@test size(output) == (10, 2, 3)\n",
    "# @test norm(output) ≈ 0.59804f0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear\n",
    "\n",
    "The `Linear` layer implements an affine transformation of its input: `w*x .+ b`. `w`\n",
    "should be initialized with small random numbers and `b` with zeros. Please review `param`\n",
    "and `param0` functions from Knet for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "param(array; atype)\n",
       "param(dims...; init, atype)\n",
       "param0(dims...; atype)\n",
       "\\end{verbatim}\n",
       "The first form returns \\texttt{Param(atype(array))}.\n",
       "\n",
       "The second form Returns a randomly initialized \\texttt{Param(atype(init(dims...)))}.  \n",
       "\n",
       "The third form \\texttt{param0} is an alias for \\texttt{param(dims...; init=zeros)}.\n",
       "\n",
       "By default, \\texttt{init} is \\texttt{xavier\\_uniform} and \\texttt{atype} is \\texttt{Knet.atype()}.\n",
       "\n"
      ],
      "text/markdown": [
       "```\n",
       "param(array; atype)\n",
       "param(dims...; init, atype)\n",
       "param0(dims...; atype)\n",
       "```\n",
       "\n",
       "The first form returns `Param(atype(array))`.\n",
       "\n",
       "The second form Returns a randomly initialized `Param(atype(init(dims...)))`.  \n",
       "\n",
       "The third form `param0` is an alias for `param(dims...; init=zeros)`.\n",
       "\n",
       "By default, `init` is `xavier_uniform` and `atype` is `Knet.atype()`.\n"
      ],
      "text/plain": [
       "\u001b[36m  param(array; atype)\u001b[39m\n",
       "\u001b[36m  param(dims...; init, atype)\u001b[39m\n",
       "\u001b[36m  param0(dims...; atype)\u001b[39m\n",
       "\n",
       "  The first form returns \u001b[36mParam(atype(array))\u001b[39m.\n",
       "\n",
       "  The second form Returns a randomly initialized \u001b[36mParam(atype(init(dims...)))\u001b[39m. \n",
       "\n",
       "  The third form \u001b[36mparam0\u001b[39m is an alias for \u001b[36mparam(dims...; init=zeros)\u001b[39m.\n",
       "\n",
       "  By default, \u001b[36minit\u001b[39m is \u001b[36mxavier_uniform\u001b[39m and \u001b[36matype\u001b[39m is \u001b[36mKnet.atype()\u001b[39m."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@doc param0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Linear; w; b; end\n",
    "\n",
    "function Linear(inputsize::Int, outputsize::Int)\n",
    "    Linear(param(outputsize, inputsize), (param0(outputsize)))\n",
    "end\n",
    "\n",
    "function (l::Linear)(x)\n",
    "    return l.w * x .+ l.b\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Testing Linear\n",
      "└ @ Main In[15]:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@info \"Testing Linear\"\n",
    "Knet.seed!(1)\n",
    "linear = Linear(100,10)\n",
    "input = oftype(linear.w, randn(Float32, 100, 5))\n",
    "output = linear(input)\n",
    "@test size(output) == (10, 5)\n",
    "# @test norm(output) ≈ 5.5301356f0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NNLM\n",
    "\n",
    "`NNLM` is the model object. It has the following fields:\n",
    "* vocab: The `Vocab` object associated with this model.\n",
    "* windowsize: How many words of history the model looks at (ngram order).\n",
    "* embed: An `Embed` layer.\n",
    "* hidden: A `Linear` layer which should be followed by `tanh.` to produce the hidden activations.\n",
    "* output: A `Linear` layer to map hidden activations to vocabulary scores.\n",
    "* dropout: A number between 0 and 1 indicating dropout probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct NNLM; vocab; windowsize; embed; hidden; output; dropout; end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constructor for `NNLM` takes a vocabulary and various size parameters, returns an\n",
    "`NNLM` object. Remember that the embeddings for `windowsize` words will be concatenated\n",
    "before being fed to the hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NNLM"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function NNLM(vocab::Vocab, windowsize::Int, embedsize::Int, hiddensize::Int, dropout::Real)\n",
    "    return NNLM(\n",
    "        vocab,\n",
    "        windowsize,\n",
    "        Embed(length(vocab.w2i), embedsize),\n",
    "        Linear(embedsize * windowsize, hiddensize),\n",
    "        Linear(hiddensize, length(vocab.w2i)),\n",
    "        dropout\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default model parameters\n",
    "HIST = 3\n",
    "EMBED = 128\n",
    "HIDDEN = 128\n",
    "DROPOUT = 0.5\n",
    "VOCAB = length(train_vocab.i2w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Testing NNLM\n",
      "└ @ Main In[32]:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@info \"Testing NNLM\"\n",
    "model = NNLM(train_vocab, HIST, EMBED, HIDDEN, DROPOUT)\n",
    "@test model.vocab === train_vocab\n",
    "@test model.windowsize === HIST\n",
    "@test size(model.embed.w) == (EMBED,VOCAB)\n",
    "@test size(model.hidden.w) == (HIDDEN,HIST*EMBED)\n",
    "@test size(model.hidden.b) == (HIDDEN,)\n",
    "@test size(model.output.w) == (VOCAB,HIDDEN)\n",
    "@test size(model.output.b) == (VOCAB,)\n",
    "@test model.dropout == 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. One word at a time\n",
    "\n",
    "Conceptually the easiest way to implement the neural language model is by processing one\n",
    "word at a time. This is also computationally the most expensive, which we will address in\n",
    "upcoming parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pred_v1\n",
    "\n",
    "`pred_v1` takes a model and a `windowsize` length vector of integer word ids indicating the\n",
    "current history, and returns a vocabulary sized vector of scores for the next word. The\n",
    "embeddings of the `windowsize` words are reshaped to a single vector before being fed to the\n",
    "hidden layer. The hidden output is passed through elementwise `tanh` before being fed to\n",
    "the output layer. Dropout is applied to embedding and hidden outputs.\n",
    "\n",
    "Please review Julia functions `vec`, `reshape`, `tanh`, and Knet function `dropout`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred_v1 (generic function with 1 method)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function pred_v1(m::NNLM, hist::AbstractVector{Int})\n",
    "    @assert length(hist) == m.windowsize\n",
    "    embed_out = dropout(m.embed(hist), m.dropout)\n",
    "    embed_out = reshape(embed_out, length(embed_out))\n",
    "    hidd_out = tanh.(dropout(m.hidden(embed_out), m.dropout))\n",
    "    output = m.output(hidd_out)\n",
    "    return output\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Testing pred_v1\n",
      "└ @ Main In[252]:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@info \"Testing pred_v1\"\n",
    "h = repeat([model.vocab.eos], model.windowsize)\n",
    "p = pred_v1(model, h)\n",
    "@test size(p) == size(train_vocab.i2w)\n",
    "\n",
    "\n",
    "# This predicts the scores for the whole sentence, will be used for later testing.\n",
    "function scores_v1(model, sent)\n",
    "    hist = repeat([ model.vocab.eos ], model.windowsize)\n",
    "    scores = []\n",
    "    for word in [ sent; model.vocab.eos ]\n",
    "        push!(scores, pred_v1(model, hist))\n",
    "        hist = [ hist[2:end]; word ]\n",
    "    end\n",
    "    hcat(scores...)\n",
    "end\n",
    "\n",
    "sent = first(train_sentences)\n",
    "@test size(scores_v1(model, sent)) == (length(train_vocab.i2w), length(sent)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate\n",
    "\n",
    "`generate` takes a model `m` and generates a random sentence of maximum length\n",
    "`maxlength`. It initializes a history of `m.windowsize` `m.vocab.eos` tokens. Then it\n",
    "computes the scores for the next word using `pred_v1` and samples a next word using\n",
    "normalized exp of scores as probabilities. It pushes this next word into history and keeps\n",
    "going until `m.vocab.eos` is picked or `maxlength` is reached. It returns a sentence\n",
    "string consisting of concatenated word strings separated by spaces.\n",
    "\n",
    "Please review Julia functions `repeat`, `push!`, `join` and StatsBase function `sample`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generate (generic function with 1 method)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function generate(m::NNLM; maxlength=30)\n",
    "    hist = repeat([m.vocab.eos], m.windowsize)\n",
    "    cur_word = m.vocab.unk\n",
    "    while length(hist)-m.windowsize < maxlength && cur_word != m.vocab.eos\n",
    "        scores = pred_v1(m, hist[length(hist)-m.windowsize+1:length(hist)])\n",
    "        # normalize props\n",
    "        scores = exp.(scores)\n",
    "        scores /= sum(scores)\n",
    "        scores = ProbabilityWeights(scores)\n",
    "        push!(hist, sample(scores))\n",
    "    end\n",
    "    return join(m.vocab.i2w[hist[m.windowsize+1:length(hist)]], \" \")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "join([io::IO,] strings [, delim [, last]])\n",
       "\\end{verbatim}\n",
       "Join an array of \\texttt{strings} into a single string, inserting the given delimiter (if any) between adjacent strings. If \\texttt{last} is given, it will be used instead of \\texttt{delim} between the last two strings. If \\texttt{io} is given, the result is written to \\texttt{io} rather than returned as as a \\texttt{String}.\n",
       "\n",
       "\\texttt{strings} can be any iterable over elements \\texttt{x} which are convertible to strings via \\texttt{print(io::IOBuffer, x)}. \\texttt{strings} will be printed to \\texttt{io}.\n",
       "\n",
       "\\section{Examples}\n",
       "\\begin{verbatim}\n",
       "julia> join([\"apples\", \"bananas\", \"pineapples\"], \", \", \" and \")\n",
       "\"apples, bananas and pineapples\"\n",
       "\n",
       "julia> join([1,2,3,4,5])\n",
       "\"12345\"\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "```\n",
       "join([io::IO,] strings [, delim [, last]])\n",
       "```\n",
       "\n",
       "Join an array of `strings` into a single string, inserting the given delimiter (if any) between adjacent strings. If `last` is given, it will be used instead of `delim` between the last two strings. If `io` is given, the result is written to `io` rather than returned as as a `String`.\n",
       "\n",
       "`strings` can be any iterable over elements `x` which are convertible to strings via `print(io::IOBuffer, x)`. `strings` will be printed to `io`.\n",
       "\n",
       "# Examples\n",
       "\n",
       "```jldoctest\n",
       "julia> join([\"apples\", \"bananas\", \"pineapples\"], \", \", \" and \")\n",
       "\"apples, bananas and pineapples\"\n",
       "\n",
       "julia> join([1,2,3,4,5])\n",
       "\"12345\"\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  join([io::IO,] strings [, delim [, last]])\u001b[39m\n",
       "\n",
       "  Join an array of \u001b[36mstrings\u001b[39m into a single string, inserting the given delimiter\n",
       "  (if any) between adjacent strings. If \u001b[36mlast\u001b[39m is given, it will be used instead\n",
       "  of \u001b[36mdelim\u001b[39m between the last two strings. If \u001b[36mio\u001b[39m is given, the result is written\n",
       "  to \u001b[36mio\u001b[39m rather than returned as as a \u001b[36mString\u001b[39m.\n",
       "\n",
       "  \u001b[36mstrings\u001b[39m can be any iterable over elements \u001b[36mx\u001b[39m which are convertible to strings\n",
       "  via \u001b[36mprint(io::IOBuffer, x)\u001b[39m. \u001b[36mstrings\u001b[39m will be printed to \u001b[36mio\u001b[39m.\n",
       "\n",
       "\u001b[1m  Examples\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  julia> join([\"apples\", \"bananas\", \"pineapples\"], \", \", \" and \")\u001b[39m\n",
       "\u001b[36m  \"apples, bananas and pineapples\"\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> join([1,2,3,4,5])\u001b[39m\n",
       "\u001b[36m  \"12345\"\u001b[39m"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@doc join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Testing generate\n",
      "└ @ Main In[130]:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@info \"Testing generate\"\n",
    "s = generate(model, maxlength=5)\n",
    "@test s isa String\n",
    "@test length(split(s)) <= 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss_v1\n",
    "\n",
    "`loss_v1` computes the negative log likelihood loss given a model `m` and sentence `sent`\n",
    "using `pred_v1`. If `average=true` it returns the per-word average loss, if\n",
    "`average=false` it returns a `(total_loss, num_words)` pair. To compute the loss it starts\n",
    "with a history of `m.windowsize` `m.vocab.eos` tokens like `generate`. Then, for each word\n",
    "in `sent` and a final `eos` token, it computes the scores based on the history, converts\n",
    "them to negative log probabilities, adds the entry corresponding to the current word to\n",
    "the total loss and pushes the current word to history.\n",
    "\n",
    "Please review Julia functions `repeat`, `vcat` and Knet functions `logp`, `nll`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_v1 (generic function with 1 method)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loss_v1(m::NNLM, sent::AbstractVector{Int}; average = true)\n",
    "    # add eos to sent\n",
    "    sent = push!(copy(sent), m.vocab.eos)\n",
    "    hist = repeat([m.vocab.eos], m.windowsize)\n",
    "    all_scores = nothing\n",
    "    cur_word = -1\n",
    "    for word in sent\n",
    "        scores = pred_v1(m, hist[length(hist)-m.windowsize+1:length(hist)])\n",
    "        scores = softmax(scores)\n",
    "        all_scores = all_scores==nothing ? scores : hcat(all_scores, scores)\n",
    "        \n",
    "        # add cur word to hist\n",
    "        push!(hist, word)\n",
    "    end\n",
    "    return nll(all_scores, sent;average=average)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Testing loss_v1\n",
      "└ @ Main In[234]:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@info \"Testing loss_v1\"\n",
    "s = first(train_sentences)\n",
    "avgloss = loss_v1(model,s)\n",
    "(tot, cnt) = loss_v1(model, s, average = false)\n",
    "@test 9 < avgloss < 10\n",
    "@test cnt == length(s) + 1\n",
    "@test tot/cnt ≈ avgloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### maploss\n",
    "\n",
    "`maploss` takes a loss function `lossfn`, a model `model` and a dataset `data` and returns\n",
    "the average per word negative log likelihood loss if `average=true` or `(total_loss,num_words)`\n",
    "if `average=false`. `data` may be an iterator over sentences (e.g. `TextReader`) or batches\n",
    "of sentences. Computing the loss over a whole dataset is useful to monitor our performance\n",
    "during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "maploss (generic function with 1 method)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function maploss(lossfn, model, data; average = true)\n",
    "    loss = []\n",
    "    for sent in data\n",
    "        push!(loss, lossfn(model, sent; average=average))\n",
    "    end\n",
    "    if average\n",
    "        return mean(loss)\n",
    "    else\n",
    "        sum_loss(a, i) = sum((x->x[i]).(a))\n",
    "        return (sum_loss(loss, 1), sum_loss(loss, 2))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Testing maploss\n",
      "└ @ Main In[245]:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@info \"Testing maploss\"\n",
    "tst100 = collect(take(test_sentences, 100))\n",
    "avgloss = maploss(loss_v1, model, tst100)\n",
    "@test 9 < avgloss < 10\n",
    "(tot, cnt) = maploss(loss_v1, model, tst100, average = false)\n",
    "@test cnt == length(tst100) + sum(length.(tst100))\n",
    "@test tot/cnt ≈ avgloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing loss_v1\n",
    "\n",
    "Unfortunately processing data one word at a time is not very efficient. The following\n",
    "shows that we can only train about 40-50 sentences per second on a V100 GPU. The training\n",
    "data has 42068 sentences which would take about 1000 seconds or 15 minutes. We probably\n",
    "need 10-100 epochs for convergence which is getting too long for this assignment. Let's\n",
    "see if we can speed things up by processing more data in parallel.\n",
    "\n",
    "Please review Knet function `sgd!` used below as well as iterator functions `collect`,\n",
    "`take`, and [Generator\n",
    "expressions](https://docs.julialang.org/en/v1/manual/arrays/#Generator-Expressions-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Timing loss_v1 with 1000 sentences\n",
      "└ @ Main In[249]:1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 37.918156 seconds (1.40 M allocations: 37.239 GiB, 11.37% gc time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Timing loss_v1 training with 100 sentences\n",
      "└ @ Main In[249]:5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 41.532224 seconds (9.28 M allocations: 48.076 GiB, 28.21% gc time)\n"
     ]
    }
   ],
   "source": [
    "@info \"Timing loss_v1 with 1000 sentences\"\n",
    "tst1000 = collect(take(test_sentences, 1000))\n",
    "@time maploss(loss_v1, model, tst1000)\n",
    "\n",
    "@info \"Timing loss_v1 training with 100 sentences\"\n",
    "trn100 = ((model,x) for x in collect(take(train_sentences, 100)))\n",
    "@time sgd!(loss_v1, trn100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5. One sentence at a time\n",
    "\n",
    "We may have to do things one word at a time when generating a sentence, but there is no\n",
    "reason not to do things in parallel for loss calculation. In this part you will implement\n",
    "`pred_v2` and `loss_v2` which do calculations for the whole sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pred_v2\n",
    "\n",
    "`pred_v2` takes a model `m`, an N×S array of word ids `hist` and produces a V×S array of\n",
    "scores where N is `m.windowsize`, V is the vocabulary size and `S` is sentence length\n",
    "including the final eos token. The `hist` array has already been padded and shifted such\n",
    "that `hist[:,i]` is the N word context to predict word i. `pred_v2` starts by finding the\n",
    "embeddings for all hist entries at once, a E×N×S array where E is the embedding size. The\n",
    "N embeddings for each context are concatenated by reshaping this array to (E*N)×S. After a\n",
    "dropout step, the hidden layer converts this to an H×S array where H is the hidden\n",
    "size. Following a `tanh` and `dropout`, the output layer produces the final result as a\n",
    "V×S array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×3 Array{Array{Float64,1},2}:\n",
       " [0.792528, 1.58506, 2.37758]  …  [0.97457, 1.94914, 2.92371]\n",
       " [0.560967, 1.12193, 1.6829]      [0.722808, 1.44562, 2.16842]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst(x) = [x * 1, x * 2, x * 3]\n",
    "arr = rand(2, 3)\n",
    "res = tst.(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×6 Array{Float64,2}:\n",
       " 0.792528  0.560967  0.864344  0.189394  0.97457  0.722808\n",
       " 1.58506   1.12193   1.72869   0.378788  1.94914  1.44562\n",
       " 2.37758   1.6829    2.59303   0.568182  2.92371  2.16842"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = hcat(res...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(c)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred_v2 (generic function with 1 method)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function pred_v2(m::NNLM, hist::AbstractMatrix{Int}) # hist: NxS\n",
    "    embed = hcat(m.embed.(hist)...) # => Ex(N*S)\n",
    "    embed = reshape(embed, size(embed)[1] * m.windowsize, size(hist)[2]) # => (E*N)xS\n",
    "    embed = dropout(embed, m.dropout)\n",
    "    hidden = dropout(m.hidden(embed), m.dropout)\n",
    "    hidden = tanh.(hidden)\n",
    "    output = m.output(hidden)\n",
    "    return output\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Testing pred_v2\n",
      "└ @ Main In[318]:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@info \"Testing pred_v2\"\n",
    "\n",
    "function scores_v2(model, sent)\n",
    "    hist = [ repeat([ model.vocab.eos ], model.windowsize); sent ]\n",
    "    hist = vcat((hist[i:end+i-model.windowsize]' for i in 1:model.windowsize)...)\n",
    "    @assert size(hist) == (model.windowsize, length(sent)+1)\n",
    "    return pred_v2(model, hist)\n",
    "end\n",
    "\n",
    "sent = first(test_sentences)\n",
    "s1, s2 = scores_v1(model, sent), scores_v2(model, sent)\n",
    "@test size(s1) == size(s2) == (length(train_vocab.i2w), length(sent)+1)\n",
    "@test s1 ≈ s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss_v2\n",
    "\n",
    "`loss_v2` computes the negative log likelihood loss given a model `m` and sentence `sent`\n",
    "using `pred_v2`. If `average=true` it returns the per-word average loss, if\n",
    "`average=false` it returns a `(total_loss, num_words)` pair. To compute the loss it\n",
    "constructs a N×S history matrix such that `hist[:,i]` gives the N word context to predict\n",
    "word i where N is `m.windowsize` and S is the sentence length + 1 for the final eos token.\n",
    "Then it computes the scores for all S tokens using `pred_v2`, converts them to negative\n",
    "log probabilities, computes the loss based on the entries for the correct words.\n",
    "\n",
    "Please review the Knet function `nll`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example for hist matrix\n",
    "# sent = [\"I\", \"am\", \"the\", \"master\"]\n",
    "# hist = [eos eos eos eos\n",
    "#         eos eos eos I\n",
    "#         eos eos I am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_v2 (generic function with 1 method)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loss_v2(m::NNLM, sent::AbstractVector{Int}; average = true)\n",
    "    # construct hist matrix\n",
    "    tmp = vcat(repeat([m.vocab.eos], m.windowsize), sent)\n",
    "    hist = hcat([tmp[i:i+m.windowsize-1] for i in 1:length(sent)]...)\n",
    "    all_scores = pred_v2(m, hist)\n",
    "    all_scores = softmax(all_scores)\n",
    "    return nll(all_scores, sent;average=average)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "take(iter, n)\n",
       "\\end{verbatim}\n",
       "An iterator that generates at most the first \\texttt{n} elements of \\texttt{iter}.\n",
       "\n",
       "\\section{Examples}\n",
       "\\begin{verbatim}\n",
       "julia> a = 1:2:11\n",
       "1:2:11\n",
       "\n",
       "julia> collect(a)\n",
       "6-element Array{Int64,1}:\n",
       "  1\n",
       "  3\n",
       "  5\n",
       "  7\n",
       "  9\n",
       " 11\n",
       "\n",
       "julia> collect(Iterators.take(a,3))\n",
       "3-element Array{Int64,1}:\n",
       " 1\n",
       " 3\n",
       " 5\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "```\n",
       "take(iter, n)\n",
       "```\n",
       "\n",
       "An iterator that generates at most the first `n` elements of `iter`.\n",
       "\n",
       "# Examples\n",
       "\n",
       "```jldoctest\n",
       "julia> a = 1:2:11\n",
       "1:2:11\n",
       "\n",
       "julia> collect(a)\n",
       "6-element Array{Int64,1}:\n",
       "  1\n",
       "  3\n",
       "  5\n",
       "  7\n",
       "  9\n",
       " 11\n",
       "\n",
       "julia> collect(Iterators.take(a,3))\n",
       "3-element Array{Int64,1}:\n",
       " 1\n",
       " 3\n",
       " 5\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  take(iter, n)\u001b[39m\n",
       "\n",
       "  An iterator that generates at most the first \u001b[36mn\u001b[39m elements of \u001b[36miter\u001b[39m.\n",
       "\n",
       "\u001b[1m  Examples\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  julia> a = 1:2:11\u001b[39m\n",
       "\u001b[36m  1:2:11\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> collect(a)\u001b[39m\n",
       "\u001b[36m  6-element Array{Int64,1}:\u001b[39m\n",
       "\u001b[36m    1\u001b[39m\n",
       "\u001b[36m    3\u001b[39m\n",
       "\u001b[36m    5\u001b[39m\n",
       "\u001b[36m    7\u001b[39m\n",
       "\u001b[36m    9\u001b[39m\n",
       "\u001b[36m   11\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> collect(Iterators.take(a,3))\u001b[39m\n",
       "\u001b[36m  3-element Array{Int64,1}:\u001b[39m\n",
       "\u001b[36m   1\u001b[39m\n",
       "\u001b[36m   3\u001b[39m\n",
       "\u001b[36m   5\u001b[39m"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@doc take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Testing loss_v2\n",
      "└ @ Main In[365]:1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\u001b[1mTest Failed\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[365]:5\u001b[22m\n",
      "  Expression: maploss(loss_v1, model, tst100) ≈ maploss(loss_v2, model, tst100)\n",
      "   Evaluated: 9.210339965071492 ≈ 9.21034035989384\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mThere was an error during testing\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mThere was an error during testing\u001b[39m",
      "",
      "Stacktrace:",
      " [1] record(::Test.FallbackTestSet, ::Union{Test.Error, Test.Fail}) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:737",
      " [2] do_test(::Test.ExecutionResult, ::Any) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:520",
      " [3] top-level scope at In[365]:5",
      " [4] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "@info \"Testing loss_v2\"\n",
    "s = first(test_sentences)\n",
    "@test loss_v1(model, s) ≈ loss_v2(model, s)\n",
    "tst100 = collect(take(test_sentences, 100))\n",
    "@test maploss(loss_v1, model, tst100) ≈ maploss(loss_v2, model, tst100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing loss_v2\n",
    "\n",
    "The following tests show that loss_v2 works about 15-20 times faster than loss_v1 during\n",
    "maploss and training. We can train at 800+ sentences/second on a V100 GPU, which is under\n",
    "a minute per epoch. We could stop here and train a reasonable model, but let's see if we\n",
    "can squeeze a bit more performance by minibatching sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Timing loss_v2  with 10K sentences\n",
      "└ @ Main In[366]:1\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mInterruptException:\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mInterruptException:\u001b[39m",
      "",
      "Stacktrace:",
      " [1] forw(::Function, ::Function, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /Users/moayedhajiali/.julia/packages/AutoGrad/TTpeo/src/core.jl:64",
      " [2] forw at /Users/moayedhajiali/.julia/packages/AutoGrad/TTpeo/src/core.jl:65 [inlined]",
      " [3] broadcasted(::typeof(+), ::Array{Float64,2}, ::Param{Array{Float32,1}}) at ./none:0",
      " [4] (::Linear)(::Array{Float64,2}) at ./In[14]:8",
      " [5] pred_v2(::NNLM, ::Array{Int64,2}) at ./In[317]:7",
      " [6] loss_v2(::NNLM, ::Array{Int64,1}; average::Bool) at ./In[354]:5",
      " [7] maploss(::Function, ::NNLM, ::Array{Array{Int64,1},1}; average::Bool) at ./In[244]:4",
      " [8] maploss(::Function, ::NNLM, ::Array{Array{Int64,1},1}) at ./In[244]:2",
      " [9] top-level scope at ./timing.jl:174 [inlined]",
      " [10] top-level scope at ./In[366]:0",
      " [11] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "@info \"Timing loss_v2  with 10K sentences\"\n",
    "tst10k = collect(take(train_sentences, 10000))\n",
    "@time maploss(loss_v2, model, tst10k)\n",
    "\n",
    "@info \"Timing loss_v2 training with 1000 sentences\"\n",
    "trn1k = ((model,x) for x in collect(take(train_sentences, 1000)))\n",
    "@time sgd!(loss_v2, trn1k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6. Multiple sentences at a time (minibatching)\n",
    "\n",
    "To get even more performance out of a GPU we will process multiple sentences at a\n",
    "time. This is called minibatching and is unfortunately complicated by the fact that the\n",
    "sentences in a batch may not be of the same length. Let's first write the minibatched\n",
    "versions of `pred` and `loss`, and see how to batch sentences together later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pred_v3\n",
    "\n",
    "`pred_v3` takes a model `m`, a N×B×S dimensional history array `hist`, and returns a V×B×S\n",
    "dimensional score array, where N is `m.windowsize`, V is the vocabulary size, B is the batch\n",
    "size, and S is maximum sentence length in the batch + 1 for the final eos token. First,\n",
    "the embeddings for all entries in `hist` are looked up, which results in an array of\n",
    "E×N×B×S where E is the embedding size. The embedding array is reshaped to (E*N)×(B*S) and\n",
    "dropout is applied. It is then fed to the hidden layer which returns a H×(B*S) hidden\n",
    "output where H is the hidden size. Following element-wise tanh and dropout, the output\n",
    "layer turns this into a score array of V×(B*S) which is reshaped and returned as a V×B×S\n",
    "dimensional tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function pred_v3(m::NNLM, hist::Array{Int})\n",
    "    # Your code here\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@info \"Testing pred_v3\"\n",
    "\n",
    "function scores_v3(model, sent)\n",
    "    hist = [ repeat([ model.vocab.eos ], model.windowsize); sent ]\n",
    "    hist = vcat((hist[i:end+i-model.windowsize]' for i in 1:model.windowsize)...)\n",
    "    @assert size(hist) == (model.windowsize, length(sent)+1)\n",
    "    hist = reshape(hist, size(hist,1), 1, size(hist,2))\n",
    "    return pred_v3(model, hist)\n",
    "end\n",
    "\n",
    "sent = first(train_sentences)\n",
    "@test scores_v2(model, sent) ≈ scores_v3(model, sent)[:,1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mask!\n",
    "\n",
    "`mask!` takes matrix `a` and a pad value `pad`. It replaces all but one of the pads at the\n",
    "end of each row with 0's. This can be used in `loss_v3` for the loss calculation: the Knet\n",
    "`nll` function skips 0's in the answer array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function mask!(a,pad)\n",
    "    # Your code here\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@info \"Testing mask!\"\n",
    "a = [1 2 1 1 1; 2 2 2 1 1; 1 1 2 2 2; 1 1 2 2 1]\n",
    "@test mask!(a,1) == [1 2 1 0 0; 2 2 2 1 0; 1 1 2 2 2; 1 1 2 2 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss_v3\n",
    "\n",
    "`loss_v3` computes the negative log likelihood loss given a model `m` and sentence\n",
    "minibatch `batch` using `pred_v3`. If `average=true` it returns the per-word average loss,\n",
    "if `average=false` it returns a `(total_loss, num_words)` pair. The batch array has\n",
    "dimensions B×S where B is the batch size and S is the length of the longest sentence in\n",
    "the batch + 1 for the final eos token. Each row contains the word ids of a sentence padded\n",
    "with eos tokens on the right.  Sentences in a batch may have different lengths. `loss_v3`\n",
    "first constructs a history array of size N×B×S from the batch such that `hist[:,i,j]`\n",
    "gives the N word context to the j'th word of the i'th sentence. This is done by repeating,\n",
    "slicing, concatenating, reshaping and/or using permutedims on the batch array. Next\n",
    "`pred_v3` is used to compute the scores array of size V×B×S where V is the vocabulary\n",
    "size. The correct answers are extracted from the batch to an array of size B×S and the\n",
    "extra padding at the end of each sentence (after the final eos) is masked (extra eos\n",
    "replaced by zeros).  Finally the scores and the masked correct answers are used to compute\n",
    "the negative log likelihood loss using `nll`.\n",
    "\n",
    "Please review array slicing, Julia functions `vcat`, `hcat`, `reshape`, `permutedims`, and\n",
    "the Knet function `nll` for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function loss_v3(m::NNLM, batch::AbstractMatrix{Int}; average = true)\n",
    "    # Your code here\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@info \"Testing loss_v3\"\n",
    "s = first(test_sentences)\n",
    "b = [ s; model.vocab.eos ]'\n",
    "@test loss_v2(model, s) ≈ loss_v3(model, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minibatching\n",
    "\n",
    "Below is a sample implementation of a sequence minibatcher. The `LMData` iterator wraps a\n",
    "TextReader and produces batches of sentences with similar length to minimize padding (too\n",
    "much padding wastes computation). To be able to scale to very large files, we do not want\n",
    "to read the whole file, sort by length etc. Instead `LMData` keeps around a small number\n",
    "of buckets and fills them with similar sized sentences from the TextReader. As soon as one\n",
    "of the buckets reaches the desired batch size it is turned into a matrix with the\n",
    "necessary padding and output. When the TextReader is exhausted the remaining buckets are\n",
    "returned (which may have smaller batch sizes). I will let you figure the rest out from the\n",
    "following, there is no code to write for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct LMData\n",
    "    src::TextReader\n",
    "    batchsize::Int\n",
    "    maxlength::Int\n",
    "    bucketwidth::Int\n",
    "    buckets\n",
    "end\n",
    "\n",
    "function LMData(src::TextReader; batchsize = 64, maxlength = typemax(Int), bucketwidth = 10)\n",
    "    numbuckets = min(128, maxlength ÷ bucketwidth)\n",
    "    buckets = [ [] for i in 1:numbuckets ]\n",
    "    LMData(src, batchsize, maxlength, bucketwidth, buckets)\n",
    "end\n",
    "\n",
    "Base.IteratorSize(::Type{LMData}) = Base.SizeUnknown()\n",
    "Base.IteratorEltype(::Type{LMData}) = Base.HasEltype()\n",
    "Base.eltype(::Type{LMData}) = Matrix{Int}\n",
    "\n",
    "function Base.iterate(d::LMData, state=nothing)\n",
    "    if state == nothing\n",
    "        for b in d.buckets; empty!(b); end\n",
    "    end\n",
    "    bucket,ibucket = nothing,nothing\n",
    "    while true\n",
    "        iter = (state === nothing ? iterate(d.src) : iterate(d.src, state))\n",
    "        if iter === nothing\n",
    "            ibucket = findfirst(x -> !isempty(x), d.buckets)\n",
    "            bucket = (ibucket === nothing ? nothing : d.buckets[ibucket])\n",
    "            break\n",
    "        else\n",
    "            sent, state = iter\n",
    "            if length(sent) > d.maxlength || length(sent) == 0; continue; end\n",
    "            ibucket = min(1 + (length(sent)-1) ÷ d.bucketwidth, length(d.buckets))\n",
    "            bucket = d.buckets[ibucket]\n",
    "            push!(bucket, sent)\n",
    "            if length(bucket) === d.batchsize; break; end\n",
    "        end\n",
    "    end\n",
    "    if bucket === nothing; return nothing; end\n",
    "    batchsize = length(bucket)\n",
    "    maxlen = maximum(length.(bucket))\n",
    "    batch = fill(d.src.vocab.eos, batchsize, maxlen + 1)\n",
    "    for i in 1:batchsize\n",
    "        batch[i, 1:length(bucket[i])] = bucket[i]\n",
    "    end\n",
    "    empty!(bucket)\n",
    "    return batch, state\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing loss_v3\n",
    "\n",
    "We can compare the speeds of `loss_v2` and `loss_v3` using various batch sizes. Running\n",
    "the following on a V100 suggests that for forward loss calculation, a batchsize around 16\n",
    "gives the best speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@info \"Timing loss_v2 and loss_v3 at various batch sizes\"\n",
    "@info loss_v2; test_collect = collect(test_sentences)\n",
    "GC.gc(); @time p2 = maploss(loss_v2, model, test_collect)\n",
    "for B in (1, 8, 16, 32, 64, 128, 256)\n",
    "    @info loss_v3,B; test_batches = collect(LMData(test_sentences, batchsize = B))\n",
    "    GC.gc(); @time p3 = maploss(loss_v3, model, test_batches); @test p3 ≈ p2\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training, a batchsize around 64 seems best, although things are a bit more complicated\n",
    "here: larger batch sizes make fewer updates per epoch which may slow down convergence. We\n",
    "will use the smaller test data to get quick results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@info \"Timing SGD for loss_v2 and loss_v3 at various batch sizes\"\n",
    "train(loss, model, data) = sgd!(loss, ((model,sent) for sent in data))\n",
    "@info loss_v2; test_collect = collect(test_sentences)\n",
    "GC.gc(); @time train(loss_v2, model, test_collect)\n",
    "for B in (1, 8, 16, 32, 64, 128, 256)\n",
    "    @info loss_v3,B; test_batches = collect(LMData(test_sentences, batchsize = B))\n",
    "    GC.gc(); @time train(loss_v3, model, test_batches)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7. Training\n",
    "\n",
    "You should be able to get the validation loss under 5.1 (perplexity under 165) in 100\n",
    "epochs with default parameters.  This takes about 5 minutes on a V100 GPU.\n",
    "\n",
    "Please review Knet function `progress!` and iterator function `ncycle` used below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NNLM(train_vocab, HIST, EMBED, HIDDEN, DROPOUT)\n",
    "train_batches = collect(LMData(train_sentences))\n",
    "valid_batches = collect(LMData(valid_sentences))\n",
    "test_batches = collect(LMData(test_sentences))\n",
    "train_batches50 = train_batches[1:50] # Small sample for quick loss calculation\n",
    "\n",
    "epoch = adam(loss_v3, ((model, batch) for batch in train_batches))\n",
    "bestmodel, bestloss = deepcopy(model), maploss(loss_v3, model, valid_batches)\n",
    "\n",
    "progress!(ncycle(epoch, 100), seconds=5) do x\n",
    "    global bestmodel, bestloss\n",
    "    # Report gradient norm for the first batch\n",
    "    f = @diff loss_v3(model, train_batches[1])\n",
    "    gnorm = sqrt(sum(norm(grad(f,x))^2 for x in params(model)))\n",
    "    # Report training and validation loss\n",
    "    trnloss = maploss(loss_v3, model, train_batches50)\n",
    "    devloss = maploss(loss_v3, model, valid_batches)\n",
    "    # Save model that does best on validation data\n",
    "    if devloss < bestloss\n",
    "        bestmodel, bestloss = deepcopy(model), devloss\n",
    "    end\n",
    "    (trn=exp(trnloss), dev=exp(devloss), ∇=gnorm)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can generate some original sentences with your trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# julia> generate(bestmodel)\n",
    "# \"the nasdaq composite index finished at N compared with ual earlier in the statement\"\n",
    "#\n",
    "# julia> generate(bestmodel)\n",
    "# \"in the pentagon joseph r. waertsilae transactions the 1\\\\/2-year transaction was oversubscribed an analyst at <unk>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 3
}
